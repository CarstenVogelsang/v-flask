# UI/E2E Tests f√ºr V-Flask

Dieses Verzeichnis enth√§lt End-to-End-Tests f√ºr V-Flask Plugins und Integrationen.

## Struktur

```
tests/ui/
‚îú‚îÄ‚îÄ README.md               # Diese Datei
‚îú‚îÄ‚îÄ specs/                  # Test-Spezifikationen (YAML)
‚îÇ   ‚îî‚îÄ‚îÄ *.yaml             # Einzelne Test-Definitionen
‚îú‚îÄ‚îÄ results/                # Test-Ergebnisse (Git-ignored)
‚îÇ   ‚îî‚îÄ‚îÄ YYYY-MM-DD_*.md    # Markdown-Reports
‚îî‚îÄ‚îÄ screenshots/            # Fehler-Screenshots (Git-ignored)
    ‚îî‚îÄ‚îÄ *.png
```

## Test-Specs ausf√ºhren

Die YAML-Spezifikationen werden von Claude Code via Playwright ausgef√ºhrt:

```bash
# Interaktiv mit Claude Code
claude "F√ºhre den E2E-Test tests/ui/specs/content-plugin-media-picker.yaml aus"
```

## Test-Spezifikation Format

Jede YAML-Spec definiert:

- **meta**: Name, Version, beteiligte Plugins/Projekte
- **prerequisites**: Ben√∂tigte Server, Credentials
- **steps**: Einzelne Testschritte mit Erwartungen
- **on_failure**: Verhalten bei Fehlern (Screenshot, Abort)

## Konventionen

1. **Keine Workarounds**: Bei Fehlern wird der echte Bug gefixt
2. **Kompletter Re-run**: Nach Fixes wird der gesamte Test wiederholt
3. **Semantische Targets**: Beschreibe UI-Elemente menschenlesbar
4. **Screenshots bei Fehlern**: Automatisch in `screenshots/` gespeichert

## Git-Ignore

Die Dateien in `results/` und `screenshots/` werden nicht versioniert:

```gitignore
tests/ui/results/
tests/ui/screenshots/
```

---

## YAML-Spec Referenz

### Vollst√§ndiges Schema

```yaml
# Test-Spezifikation f√ºr Claude Code E2E-Tests
# Format: YAML 1.2

meta:
  name: string           # Lesbare Bezeichnung des Tests
  id: string             # Eindeutige ID (kebab-case, z.B. "e2e-content-media-picker")
  version: string        # Semantic Version (z.B. "1.0")
  author: string         # Ersteller des Tests
  created: date          # Erstelldatum (YYYY-MM-DD)
  plugins: [string]      # Beteiligte V-Flask Plugins (z.B. ["content", "media"])
  projects: [string]     # Beteiligte Projekte (z.B. ["v-flask", "vz_fruehstueckenclick"])

prerequisites:
  servers:               # Ben√∂tigte Server f√ºr den Test
    - name: string       # Lesbare Bezeichnung (z.B. "Marketplace")
      command: string    # Start-Befehl (z.B. "uv run flask run --debug --port 5800")
      cwd: string        # Arbeitsverzeichnis (absoluter Pfad)
      port: number       # Port-Nummer
      health_check: url  # URL f√ºr Verf√ºgbarkeitspr√ºfung (z.B. "http://localhost:5800/")

  credentials:           # Login-Daten (Key = Referenz-Name)
    <name>:              # Referenzname f√ºr steps.credentials
      email: string
      password: string

  environment:           # Ben√∂tigte Umgebungsvariablen
    <project>:           # Projektname
      <VAR_NAME>: "required" | "optional"  # Env-Variable mit Status

steps:                   # Testschritte (werden sequenziell ausgef√ºhrt)
  - id: number           # Schrittnummer (1, 2, 3, ...)
    name: string         # Beschreibung des Schritts
    action: string       # Aktionstyp (siehe unten)
    url?: string         # F√ºr action: navigate
    target?: string      # Semantische Beschreibung des UI-Elements
    fallback_selector?: string  # CSS/Playwright-Selektor als Fallback
    value?: string       # F√ºr action: fill, select
    credentials?: string # Referenz zu prerequisites.credentials
    condition?: string   # F√ºr action: conditional_click
    server?: string      # F√ºr action: restart_server
    slot?: string        # F√ºr Seitenzuweisungen
    expect: [string]     # Erwartete Ergebnisse (Assertions)

on_failure:
  screenshot: boolean    # Screenshot bei Fehler speichern
  abort_test: boolean    # Test abbrechen bei Fehler
  log_console_errors: boolean    # Browser-Console-Errors loggen
  save_network_requests: boolean # Netzwerk-Requests speichern

cleanup: [string]        # Aufr√§umschritte (manuell beschrieben)

verification:            # Finale Pr√ºfungen
  final_checks: [string] # Liste der End-Assertions
```

### Aktionstypen (action)

| Action | Beschreibung | Ben√∂tigte Felder |
|--------|--------------|------------------|
| `navigate` | Zu URL navigieren | `url` |
| `navigate_and_login` | Navigieren + Login-Formular ausf√ºllen | `url`, `credentials` |
| `click` | Element anklicken | `target` |
| `conditional_click` | Klicken wenn Bedingung erf√ºllt | `target`, `condition` |
| `fill` | Textfeld ausf√ºllen | `target`, `value` |
| `fill_and_submit` | Ausf√ºllen + Enter dr√ºcken | `target`, `value` |
| `select` | Dropdown-Option w√§hlen | `target`, `value` |
| `restart_server` | Server neu starten | `server` |

### Semantische Targets

Statt CSS-Selektoren beschreibst du UI-Elemente menschenlesbar:

```yaml
# Gut: Semantisch
target: "Installieren-Button f√ºr Content-Plugin"
target: "Tab 'Stock-Fotos' oder 'Pexels'"
target: "Erstes Suchergebnis-Bild"

# Fallback: CSS-Selektor (wenn n√∂tig)
target: "Speichern-Button"
fallback_selector: "button[type='submit'].btn-primary"
```

---

## Prompt-Template f√ºr neue Tests

Kopiere dieses Template, um Claude Code einen neuen E2E-Test erstellen zu lassen:

```
Erstelle einen neuen E2E-Test f√ºr [FEATURE/PLUGIN].

Referenz: tests/ui/README.md (YAML-Spec Format)
Vorlage: tests/ui/specs/content-plugin-media-picker.yaml

Der Test soll pr√ºfen:
1. [Schritt 1]
2. [Schritt 2]
3. [Schritt 3]
4. ...

Beteiligte Projekte: [v-flask, vz_fruehstueckenclick, ...]
Voraussetzungen: [Server, API-Keys, ...]
```

### Beispiel-Prompts

**Plugin-Installation testen:**
```
Erstelle einen E2E-Test f√ºr das Katalog-Plugin.
Der Test soll pr√ºfen:
1. Plugin installieren via Marketplace
2. Katalog-Admin aufrufen
3. Neuen Eintrag erstellen mit Bild
Beteiligte Projekte: v-flask, vz_fruehstueckenclick
```

**Feature-Test:**
```
Erstelle einen E2E-Test f√ºr den Icon-Picker.
Der Test soll pr√ºfen:
1. Admin-Formular mit Icon-Picker √∂ffnen
2. Icon suchen und ausw√§hlen
3. Formular speichern
4. Icon wird korrekt angezeigt
```

---

## Test-Ergebnis Format

Nach jedem Testlauf wird ein Ergebnis-Dokument in `results/` erstellt:

**Dateiname:** `YYYY-MM-DD_<test-id>.md`

### Struktur

```markdown
# Test-Ergebnis: [Test-Name]

**Spec:** `specs/<filename>.yaml`
**Datum:** YYYY-MM-DD
**Status:** ‚úÖ PASSED | ‚ùå FAILED | ‚ö†Ô∏è PARTIAL
**Durchlauf:** N (optional: Hinweis auf vorherige L√§ufe)

## Zusammenfassung

| Phase | Status | Bemerkung |
|-------|--------|-----------|
| 1. [Phase] | ‚úÖ/‚ùå | [Details] |
| 2. [Phase] | ‚úÖ/‚ùå | [Details] |
| ... | ... | ... |

## Behobene Bugs (w√§hrend Test)

### Bug: [Kurzbeschreibung]

**Root Cause:** [Ursache]

**Fixes:**
- [Datei]: [√Ñnderung]

## Verifikation

- [x] [Check 1]
- [x] [Check 2]
- [ ] [Offener Punkt]
```

### Status-Definitionen

| Status | Bedeutung |
|--------|-----------|
| ‚úÖ PASSED | Alle Steps erfolgreich |
| ‚ùå FAILED | Test abgebrochen wegen Fehler |
| ‚ö†Ô∏è PARTIAL | Teilweise erfolgreich, manuelle Intervention n√∂tig |
| üîÑ PASSED (nach Bug-Fix) | Erfolgreich nach Fehlerbehebung |
